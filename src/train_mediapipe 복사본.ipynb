{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: (array([0, 1, 2]), array([8073,  837, 4894], dtype=int64))\n",
      "SMOTE applied.\n",
      "Training class distribution: (array([0, 1, 2]), array([6458, 3200, 3915], dtype=int64))\n",
      "Time noise added for data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\yolo_study\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 67ms/step - accuracy: 0.4621 - loss: 1.0596 - val_accuracy: 0.4843 - val_loss: 1.0224\n",
      "Epoch 2/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.4822 - loss: 1.0223 - val_accuracy: 0.4530 - val_loss: 1.1250\n",
      "Epoch 3/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.4606 - loss: 1.0358 - val_accuracy: 0.4869 - val_loss: 1.0060\n",
      "Epoch 4/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.5008 - loss: 1.0060 - val_accuracy: 0.5274 - val_loss: 0.9790\n",
      "Epoch 5/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - accuracy: 0.5160 - loss: 0.9811 - val_accuracy: 0.4961 - val_loss: 1.0286\n",
      "Epoch 6/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.5365 - loss: 0.9686 - val_accuracy: 0.5422 - val_loss: 0.9737\n",
      "Epoch 7/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 72ms/step - accuracy: 0.5496 - loss: 0.9484 - val_accuracy: 0.4534 - val_loss: 1.0578\n",
      "Epoch 8/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.5381 - loss: 0.9525 - val_accuracy: 0.5436 - val_loss: 0.9656\n",
      "Epoch 9/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 72ms/step - accuracy: 0.5363 - loss: 0.9540 - val_accuracy: 0.5153 - val_loss: 0.9987\n",
      "Epoch 10/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.5420 - loss: 0.9493 - val_accuracy: 0.5160 - val_loss: 1.0015\n",
      "Epoch 11/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.5279 - loss: 0.9547 - val_accuracy: 0.5481 - val_loss: 0.9419\n",
      "Epoch 12/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - accuracy: 0.5493 - loss: 0.9376 - val_accuracy: 0.5540 - val_loss: 0.9384\n",
      "Epoch 13/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5516 - loss: 0.9348 - val_accuracy: 0.5444 - val_loss: 0.9534\n",
      "Epoch 14/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5516 - loss: 0.9288 - val_accuracy: 0.5370 - val_loss: 0.9509\n",
      "Epoch 15/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 66ms/step - accuracy: 0.5604 - loss: 0.9232 - val_accuracy: 0.5584 - val_loss: 0.9333\n",
      "Epoch 16/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5568 - loss: 0.9235 - val_accuracy: 0.5344 - val_loss: 0.9503\n",
      "Epoch 17/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.5577 - loss: 0.9225 - val_accuracy: 0.5238 - val_loss: 0.9945\n",
      "Epoch 18/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - accuracy: 0.5606 - loss: 0.9255 - val_accuracy: 0.5451 - val_loss: 0.9327\n",
      "Epoch 19/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5597 - loss: 0.9236 - val_accuracy: 0.5204 - val_loss: 0.9856\n",
      "Epoch 20/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.5565 - loss: 0.9292 - val_accuracy: 0.5525 - val_loss: 0.9278\n",
      "Epoch 21/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.5611 - loss: 0.9239 - val_accuracy: 0.5462 - val_loss: 0.9354\n",
      "Epoch 22/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5618 - loss: 0.9178 - val_accuracy: 0.5407 - val_loss: 0.9448\n",
      "Epoch 23/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 66ms/step - accuracy: 0.5507 - loss: 0.9385 - val_accuracy: 0.5470 - val_loss: 0.9325\n",
      "Epoch 24/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - accuracy: 0.5527 - loss: 0.9227 - val_accuracy: 0.5311 - val_loss: 0.9681\n",
      "Epoch 25/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - accuracy: 0.5686 - loss: 0.9136 - val_accuracy: 0.5374 - val_loss: 0.9510\n",
      "Epoch 26/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5616 - loss: 0.9233 - val_accuracy: 0.5562 - val_loss: 0.9221\n",
      "Epoch 27/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.5537 - loss: 0.9232 - val_accuracy: 0.5573 - val_loss: 0.9249\n",
      "Epoch 28/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - accuracy: 0.5565 - loss: 0.9119 - val_accuracy: 0.5201 - val_loss: 0.9595\n",
      "Epoch 29/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5625 - loss: 0.9164 - val_accuracy: 0.5573 - val_loss: 0.9223\n",
      "Epoch 30/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5675 - loss: 0.9125 - val_accuracy: 0.5551 - val_loss: 0.9196\n",
      "Epoch 31/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.5637 - loss: 0.9181 - val_accuracy: 0.5573 - val_loss: 0.9277\n",
      "Epoch 32/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.5649 - loss: 0.9137 - val_accuracy: 0.5492 - val_loss: 0.9309\n",
      "Epoch 33/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.5511 - loss: 0.9234 - val_accuracy: 0.5543 - val_loss: 0.9253\n",
      "Epoch 34/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.5555 - loss: 0.9130 - val_accuracy: 0.5554 - val_loss: 0.9261\n",
      "Epoch 35/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5642 - loss: 0.9053 - val_accuracy: 0.5436 - val_loss: 0.9403\n",
      "Epoch 36/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - accuracy: 0.5682 - loss: 0.9146 - val_accuracy: 0.5606 - val_loss: 0.9175\n",
      "Epoch 37/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 66ms/step - accuracy: 0.5619 - loss: 0.9071 - val_accuracy: 0.5510 - val_loss: 0.9251\n",
      "Epoch 38/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 70ms/step - accuracy: 0.5714 - loss: 0.8988 - val_accuracy: 0.5606 - val_loss: 0.9125\n",
      "Epoch 39/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5699 - loss: 0.8924 - val_accuracy: 0.5687 - val_loss: 0.9010\n",
      "Epoch 40/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.5694 - loss: 0.9053 - val_accuracy: 0.5687 - val_loss: 0.9072\n",
      "Epoch 41/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 77ms/step - accuracy: 0.5623 - loss: 0.9016 - val_accuracy: 0.5705 - val_loss: 0.8926\n",
      "Epoch 42/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.5703 - loss: 0.8900 - val_accuracy: 0.5731 - val_loss: 0.8925\n",
      "Epoch 43/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.5653 - loss: 0.8876 - val_accuracy: 0.5716 - val_loss: 0.8933\n",
      "Epoch 44/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.5738 - loss: 0.8825 - val_accuracy: 0.5617 - val_loss: 0.9076\n",
      "Epoch 45/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5697 - loss: 0.8828 - val_accuracy: 0.5506 - val_loss: 0.9134\n",
      "Epoch 46/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 75ms/step - accuracy: 0.5723 - loss: 0.8958 - val_accuracy: 0.5672 - val_loss: 0.8995\n",
      "Epoch 47/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 72ms/step - accuracy: 0.5801 - loss: 0.8893 - val_accuracy: 0.5691 - val_loss: 0.8963\n",
      "Epoch 48/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.5722 - loss: 0.8850 - val_accuracy: 0.5669 - val_loss: 0.8975\n",
      "Epoch 49/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5655 - loss: 0.8875 - val_accuracy: 0.5687 - val_loss: 0.8943\n",
      "Epoch 50/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.5772 - loss: 0.8785 - val_accuracy: 0.5720 - val_loss: 0.8940\n",
      "Epoch 51/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5771 - loss: 0.8728 - val_accuracy: 0.5713 - val_loss: 0.8900\n",
      "Epoch 52/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 75ms/step - accuracy: 0.5745 - loss: 0.8816 - val_accuracy: 0.5731 - val_loss: 0.9032\n",
      "Epoch 53/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.5769 - loss: 0.8822 - val_accuracy: 0.5757 - val_loss: 0.8949\n",
      "Epoch 54/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.5840 - loss: 0.8730 - val_accuracy: 0.5764 - val_loss: 0.8970\n",
      "Epoch 55/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.5810 - loss: 0.8809 - val_accuracy: 0.5720 - val_loss: 0.8937\n",
      "Epoch 56/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.5835 - loss: 0.8752 - val_accuracy: 0.5698 - val_loss: 0.8914\n",
      "Epoch 57/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.5726 - loss: 0.8785 - val_accuracy: 0.5720 - val_loss: 0.8880\n",
      "Epoch 58/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - accuracy: 0.5864 - loss: 0.8722 - val_accuracy: 0.5731 - val_loss: 0.8878\n",
      "Epoch 59/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.5844 - loss: 0.8751 - val_accuracy: 0.5742 - val_loss: 0.8906\n",
      "Epoch 60/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.5786 - loss: 0.8739 - val_accuracy: 0.5727 - val_loss: 0.8902\n",
      "Epoch 61/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.5730 - loss: 0.8800 - val_accuracy: 0.5735 - val_loss: 0.8845\n",
      "Epoch 62/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 77ms/step - accuracy: 0.5769 - loss: 0.8659 - val_accuracy: 0.5742 - val_loss: 0.8827\n",
      "Epoch 63/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 79ms/step - accuracy: 0.5651 - loss: 0.8817 - val_accuracy: 0.5654 - val_loss: 0.8883\n",
      "Epoch 64/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.5712 - loss: 0.8834 - val_accuracy: 0.5713 - val_loss: 0.8918\n",
      "Epoch 65/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5682 - loss: 0.8793 - val_accuracy: 0.5738 - val_loss: 0.8903\n",
      "Epoch 66/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.5821 - loss: 0.8668 - val_accuracy: 0.5786 - val_loss: 0.8878\n",
      "Epoch 67/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 74ms/step - accuracy: 0.5809 - loss: 0.8777 - val_accuracy: 0.5738 - val_loss: 0.8833\n",
      "Epoch 68/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - accuracy: 0.5796 - loss: 0.8750 - val_accuracy: 0.5691 - val_loss: 0.8927\n",
      "Epoch 69/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.5748 - loss: 0.8743 - val_accuracy: 0.5761 - val_loss: 0.8898\n",
      "Epoch 70/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 76ms/step - accuracy: 0.5757 - loss: 0.8833 - val_accuracy: 0.5691 - val_loss: 0.9022\n",
      "Epoch 71/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.5794 - loss: 0.8739 - val_accuracy: 0.5716 - val_loss: 0.9004\n",
      "Epoch 72/100\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - accuracy: 0.5748 - loss: 0.8768 - val_accuracy: 0.5786 - val_loss: 0.8859\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.5873 - loss: 0.8675\n",
      "Test Loss: 0.8752539157867432, Test Accuracy: 0.5798467993736267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, Attention\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "\n",
    "# Step 1: Load Data\n",
    "data = pd.read_csv(r'.\\keypoints_output_with_filename.csv')\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "# Remove 'fall' from 'image_fall_num' and convert to integer\n",
    "data['image_fall_num'] = data['image_fall_num'].str.replace('fall', '').astype(int)\n",
    "\n",
    "# Sort and group by 'image_fall_num'\n",
    "data = data.sort_values(by=['image_fall_num', 'image_num'])  # Assume 'frame_index' indicates temporal order\n",
    "groups = data.groupby('image_fall_num')\n",
    "\n",
    "# Extract sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "for _, group in groups:\n",
    "    # Select only numeric columns and handle non-numeric values\n",
    "    numeric_data = group.iloc[:, 2:-1].apply(pd.to_numeric, errors='coerce')  # Convert to numeric, NaN if not possible\n",
    "    numeric_data = numeric_data.fillna(0)  # Replace NaN with 0 or another strategy\n",
    "    sequences.append(numeric_data.values)\n",
    "    \n",
    "    # Store all labels in the group instead of just one\n",
    "    labels.extend(group['label'].values)  # Append all labels from the group\n",
    "\n",
    "# Padding sequences to the same length\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "num_features = sequences[0].shape[1]\n",
    "\n",
    "padded_sequences = np.zeros((len(labels), max_seq_length, num_features))\n",
    "label_array = np.array(labels, dtype=int)\n",
    "\n",
    "idx = 0\n",
    "for i, seq in enumerate(sequences):\n",
    "    for _ in range(len(seq)):\n",
    "        padded_sequences[idx, :len(seq), :] = seq\n",
    "        idx += 1\n",
    "\n",
    "# Ensure at least two classes before applying SMOTE\n",
    "if len(np.unique(label_array)) < 2:\n",
    "    minority_class = 1 if 1 in label_array else 2\n",
    "    label_array = np.concatenate([label_array, np.full(5, minority_class)])  # Add missing class\n",
    "\n",
    "# Check class distribution before SMOTE\n",
    "print(\"Original class distribution:\", np.unique(label_array, return_counts=True))\n",
    "\n",
    "# Normalize the sequences\n",
    "scaler = MinMaxScaler()\n",
    "num_samples, seq_length, num_features = padded_sequences.shape\n",
    "reshaped_sequences = padded_sequences.reshape(-1, num_features)\n",
    "norm_sequences = scaler.fit_transform(reshaped_sequences)\n",
    "norm_sequences = norm_sequences.reshape(num_samples, seq_length, num_features)\n",
    "\n",
    "# Apply SMOTE BEFORE train-test split\n",
    "unique_classes = np.unique(label_array)\n",
    "if len(unique_classes) > 1:\n",
    "    smote = SMOTE(sampling_strategy={1: 4000}, random_state=42)\n",
    "    norm_sequences_reshaped = norm_sequences.reshape(num_samples, -1)  # 2D 변환\n",
    "    norm_sequences_resampled, labels_resampled = smote.fit_resample(norm_sequences_reshaped, label_array)\n",
    "    # Reshape back to 3D\n",
    "    num_samples_resampled = norm_sequences_resampled.shape[0]\n",
    "    norm_sequences_resampled = norm_sequences_resampled.reshape(num_samples_resampled, max_seq_length, num_features)\n",
    "    print(\"SMOTE applied.\")\n",
    "else:\n",
    "    print(\"SMOTE not applied as only one class is present in dataset\")\n",
    "    norm_sequences_resampled, labels_resampled = norm_sequences, label_array\n",
    "\n",
    "# Train-test split AFTER SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    norm_sequences_resampled, labels_resampled, test_size=0.2, random_state=42, stratify=labels_resampled\n",
    ")\n",
    "\n",
    "# Check class distribution in training data\n",
    "print(\"Training class distribution:\", np.unique(y_train, return_counts=True))\n",
    "\n",
    "# Data Augmentation: Add Time Noise\n",
    "\n",
    "def add_time_noise(data, noise_level=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=noise_level, size=data.shape)\n",
    "    return data + noise\n",
    "\n",
    "X_train = np.array([add_time_noise(seq) for seq in X_train])\n",
    "print(\"Time noise added for data augmentation.\")\n",
    "\n",
    "# Convert labels back to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Step 3: Define the Model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True, input_shape=(max_seq_length, num_features))),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(32, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # Multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the Model\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "#model.save('fall_detection_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load Data\n",
    "data = pd.read_csv(r'.\\keypoints_output_with_filename.csv')\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "data['image_fall_num'] = data['image_fall_num'].str.replace('fall', '').astype(int)\n",
    "data = data.sort_values(by=['image_fall_num', 'image_num'])  \n",
    "groups = data.groupby('image_fall_num')\n",
    "\n",
    "# Extract sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "for _, group in groups:\n",
    "    numeric_data = group.iloc[:, 2:-1].apply(pd.to_numeric, errors='coerce')\n",
    "    numeric_data = numeric_data.fillna(0)\n",
    "    sequences.append(numeric_data.values)\n",
    "    labels.extend(group['label'].values)  \n",
    "\n",
    "# Padding sequences to the same length\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "num_features = sequences[0].shape[1]\n",
    "\n",
    "padded_sequences = np.zeros((len(labels), max_seq_length, num_features))\n",
    "label_array = np.array(labels, dtype=int)\n",
    "\n",
    "idx = 0\n",
    "for i, seq in enumerate(sequences):\n",
    "    for _ in range(len(seq)):\n",
    "        padded_sequences[idx, :len(seq), :] = seq\n",
    "        idx += 1\n",
    "\n",
    "# Normalize the sequences\n",
    "scaler = MinMaxScaler()\n",
    "num_samples, seq_length, num_features = padded_sequences.shape\n",
    "reshaped_sequences = padded_sequences.reshape(-1, num_features)\n",
    "norm_sequences = scaler.fit_transform(reshaped_sequences)\n",
    "norm_sequences = norm_sequences.reshape(num_samples, seq_length, num_features)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    norm_sequences, label_array, test_size=0.2, random_state=42, stratify=label_array\n",
    ")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# PyTorch Model Definition\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pe = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers, output_dim):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=ff_dim, \n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])  \n",
    "        return self.softmax(x)\n",
    "\n",
    "# Define Model Parameters\n",
    "input_dim = num_features\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "num_layers = 6\n",
    "output_dim = 3  # Multi-class classification\n",
    "\n",
    "# Instantiate Model\n",
    "model = TransformerEncoderModel(input_dim, embed_dim, num_heads, ff_dim, num_layers, output_dim)\n",
    "\n",
    "# Loss Function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "# Convert Data to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long)\n",
    "\n",
    "# PyTorch DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "patience = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == batch_y).sum().item()\n",
    "            val_total += batch_y.size(0)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_transformer_model.pth\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"Training Complete. Best model saved.\")\n",
    "\n",
    "# Load Best Model\n",
    "model.load_state_dict(torch.load(\"best_transformer_model.pth\"))\n",
    "\n",
    "# Test Model Performance\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        outputs = model(batch_x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_correct += (predicted == batch_y).sum().item()\n",
    "        test_total += batch_y.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
